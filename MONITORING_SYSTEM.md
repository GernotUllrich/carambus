# üîç Scraping Monitoring System - Komplett-√úbersicht

**Implementiert am: 2026-02-15**

---

## üéØ Zielsetzung

Statt aufw√§ndiger Mock-Tests: **Real-World Production Monitoring**

### Problem (vorher):
- ‚ùå Aufw√§ndige Fixture-Tests (>500 Zeilen Mock-Data)
- ‚ùå Veralten schnell (ClubCloud √§ndert sich)
- ‚ùå Zeigen nicht echte Probleme
- ‚ùå Hoher Maintenance-Aufwand

### L√∂sung (jetzt):
- ‚úÖ **Automatic Exception Tracking**
- ‚úÖ **Performance Monitoring**
- ‚úÖ **Create/Update/Delete Statistiken**
- ‚úÖ **Code-Coverage** (welche Methoden laufen wirklich?)
- ‚úÖ **Anomalie-Erkennung** (automatische Alerts)
- ‚úÖ **Web-Dashboard** + CLI Tools
- ‚úÖ **Null Maintenance** (selbst-aktualisierend)

---

## üì¶ Komponenten

### 1. Backend (Models & Concerns)

#### `app/models/concerns/scraping_monitor.rb`
- **Concern** zum Einbinden in Scraping-Klassen
- Trackt automatisch: Exceptions, Performance, DB-√Ñnderungen
- Callbacks: `record_created`, `record_updated`, `record_deleted`, `record_error`
- Methoden-Tracking f√ºr Code-Coverage

#### `app/models/scraping_log.rb`
- **Model** f√ºr Persistierung der Monitoring-Daten
- Scopes: `recent`, `by_operation`, `with_errors`, `today`, `last_week`
- Statistik-Methoden: `stats_for()`, `all_operations_stats()`
- Anomalie-Erkennung: `check_anomalies()`
- Cleanup: `cleanup_old_logs(keep_days)`

#### Migrations
- `db/migrate/20260215194955_create_scraping_logs.rb`
  - Tabelle: `scraping_logs`
  - Felder: operation, context, duration, created_count, updated_count, deleted_count, unchanged_count, error_count, errors_json, executed_at
  - Indizes: operation, executed_at, [operation, executed_at]

- `db/migrate/20260215195121_add_unchanged_count_to_scraping_logs.rb`
  - Erg√§nzt: `unchanged_count` Feld

### 2. Frontend (Web-Dashboard)

#### `app/controllers/scraping_monitor_controller.rb`
- **Dashboard-Controller**
- Actions: `index` (√úbersicht), `operation` (Detail-View)
- Filtert nach Zeitr√§umen (1/7/30/90 Tage)

#### Views
- `app/views/scraping_monitor/index.html.erb`
  - √úbersicht aller Operationen
  - Stats-Cards (Created/Updated/Deleted/Errors)
  - Operations-Tabelle mit Erfolgsrate
  - Recent Logs (letzte 50)
  - Auto-Refresh alle 30 Sekunden

- `app/views/scraping_monitor/operation.html.erb`
  - Detail-View f√ºr einzelne Operation
  - Execution History (letzte 100 Runs)
  - Performance-Trends
  - Error-Details (aufklappbar)

#### Routes
```ruby
get 'scraping_monitor', to: 'scraping_monitor#index'
get 'scraping_monitor/:id', to: 'scraping_monitor#operation'
```

### 3. CLI Tools (Rake Tasks)

#### `lib/tasks/scrape_monitored.rake`

| Task | Beschreibung |
|------|--------------|
| `rake scrape:daily_update_monitored` | Daily Scraping **mit Monitoring** |
| `rake scrape:stats` | Statistiken anzeigen (alle Operationen) |
| `rake scrape:stats[operation]` | Stats f√ºr spezifische Operation |
| `rake scrape:check_health` | Health Check (Exit Code 1 bei Anomalien) |
| `rake scrape:recent_errors` | Letzte Errors (24h) |
| `rake scrape:cleanup_logs[days]` | Alte Logs entfernen (default: 90 Tage) |
| `rake scrape:export_stats[days]` | CSV Export f√ºr Analyse |

---

## üöÄ Setup

### 1. Migrations ausf√ºhren

```bash
cd /Volumes/EXT2TB/gullrich/DEV/carambus/carambus_master
bin/rails db:migrate
```

### 2. Testen

```bash
# Test-Scraping mit Monitoring
rake scrape:daily_update_monitored

# Stats ansehen
rake scrape:stats
```

### 3. Dashboard √∂ffnen

```bash
bin/rails server
open http://localhost:3000/scraping_monitor
```

---

## üìä Was wird getrackt?

### Pro Scraping-Operation:

| Metrik | Typ | Beschreibung |
|--------|-----|--------------|
| `operation` | String | Name der Operation (z.B. "daily_update") |
| `context` | String | Kontext (z.B. "Region[5]") |
| `duration` | Float | Laufzeit in Sekunden |
| `created_count` | Integer | Neue Records erstellt |
| `updated_count` | Integer | Records aktualisiert |
| `deleted_count` | Integer | Records gel√∂scht |
| `unchanged_count` | Integer | Records unver√§ndert |
| `error_count` | Integer | Anzahl Fehler |
| `errors_json` | Text | Vollst√§ndige Exceptions (JSON) |
| `executed_at` | DateTime | Zeitpunkt der Ausf√ºhrung |

### Exception Details (errors_json):

```json
[
  {
    "context": "Tournament[123]",
    "error": {
      "class": "NoMethodError",
      "message": "undefined method `cc_id' for nil:NilClass",
      "backtrace": [
        "app/models/tournament.rb:395",
        "lib/tasks/scrape.rake:45",
        "..."
      ]
    }
  }
]
```

---

## üö® Anomalie-Erkennung

Das System erkennt **automatisch**:

### 1. Hohe Error-Rate
```ruby
if success_rate < 90%
  ‚Üí ‚ö†Ô∏è ALARM: "High error rate"
end
```

### 2. Performance-Probleme
```ruby
if avg_duration > 300  # 5 Minuten
  ‚Üí ‚ö†Ô∏è ALARM: "Slow performance"
end
```

### Pr√ºfen:
```bash
rake scrape:check_health

# Exit Code 0: OK
# Exit Code 1: Anomalien gefunden (f√ºr CI/CD)
```

---

## üîß Integration in bestehenden Code

### Beispiel 1: Concern nutzen

```ruby
class Tournament < ApplicationRecord
  include ScrapeMonitor
  
  def scrape_tournaments
    track_scraping("tournament_scraping") do |monitor|
      tournaments.each do |t|
        begin
          if t.scrape_single_tournament_public
            monitor.record_updated(t)
          else
            monitor.record_unchanged(t)
          end
          monitor.track_method("scrape_single_tournament_public")
        rescue => e
          monitor.record_error(t, e)
        end
      end
    end
  end
end
```

### Beispiel 2: Manuelles Monitoring

```ruby
monitor = ScrapingMonitor.new("my_operation", "MyContext")

monitor.run do |m|
  # Dein Scraping-Code
  
  data.each do |item|
    begin
      record = create_from(item)
      m.record_created(record)
    rescue => e
      m.record_error(item, e)
    end
  end
  
  m.track_method("create_from")
end
```

---

## üìà Langfristige Auswertung

### Model-Methoden

```ruby
# Stats f√ºr Operation (letzte 7 Tage)
ScrapingLog.stats_for("daily_update", since: 7.days.ago)
# => {
#      total_runs: 7,
#      avg_duration: 125.3,
#      total_created: 123,
#      total_updated: 456,
#      total_deleted: 12,
#      total_errors: 5,
#      success_rate: 98.9,
#      last_run: 2026-02-15 03:00:00
#    }

# Alle Operations-Stats
ScrapingLog.all_operations_stats(since: 30.days.ago)

# Anomalien pr√ºfen
ScrapingLog.check_anomalies(threshold: 0.1)

# Logs mit Errors
ScrapingLog.with_errors.last_week

# Cleanup
ScrapingLog.cleanup_old_logs(keep_days: 90)
```

### CSV Export

```bash
rake scrape:export_stats[30]
# ‚Üí tmp/scraping_stats_2026-02-15.csv

# Spalten:
# Operation, Executed At, Duration (s), Created, Updated, Deleted, Errors
```

---

## üéØ Code-Coverage durch Monitoring

Das Monitoring zeigt welche Methoden **tats√§chlich in Production** laufen:

```ruby
monitor.track_method("scrape_single_tournament_public")
monitor.track_method("scrape_locations")
monitor.track_method("scrape_clubs")
```

**Log-Output:**
```
üìä ScrapeMonitor Summary: region_scraping
   Methods called: scrape_single_tournament_public, scrape_locations, scrape_clubs
```

**Vorteile gegen√ºber SimpleCov:**
- ‚úÖ Zeigt **echte Produktions-Ausf√ºhrungen**
- ‚úÖ Zeigt **Performance** je Methode
- ‚úÖ Zeigt **echte Exceptions**
- ‚úÖ Zeigt **Dead Code** (nie aufgerufene Methoden)

---

## üîÆ Zuk√ºnftige Erweiterungen (Optional)

### Geplant:
- [ ] **Grafana/Prometheus Integration**
  - Metriken exportieren via `/metrics` Endpoint
  - Grafana-Dashboard f√ºr Visualisierung

- [ ] **Slack/Discord Webhooks**
  - Automatische Benachrichtigung bei Errors
  - Daily Summary Reports

- [ ] **Automatische Retry**
  - Bei tempor√§ren Fehlern (Timeout, 503)
  - Exponential Backoff

- [ ] **Diff-Tracking**
  - Welche Felder √§ndern sich?
  - Before/After Snapshots

- [ ] **HTML-Snapshot-Archivierung**
  - Bei Errors automatisch HTML speichern
  - F√ºr Debugging & Regression-Tests

### Nice-to-have:
- [ ] **Charts im Dashboard** (Chart.js)
- [ ] **Email-Reports** (t√§glich/w√∂chentlich)
- [ ] **ClubCloud Changelog-Detection**
- [ ] **Automatische Fixture-Generierung**

---

## üìö Dokumentation

### Erstellt:
- ‚úÖ `docs/SCRAPING_MONITORING.md` - Vollst√§ndige Dokumentation
- ‚úÖ `docs/SCRAPING_MONITORING_QUICKSTART.md` - 5-Minuten Quick Start
- ‚úÖ `MONITORING_SYSTEM.md` (dieses Dokument) - Komplett-√úbersicht

### Aktualisiert:
- ‚úÖ `test/README.md` - Verweis auf Monitoring hinzugef√ºgt

---

## üéØ Empfohlener Workflow

### Entwicklung:
```bash
# 1. Lokal testen mit Monitoring
rake scrape:daily_update_monitored

# 2. Stats pr√ºfen
rake scrape:stats

# 3. Dashboard √∂ffnen
open http://localhost:3000/scraping_monitor
```

### Deployment:
```bash
# 1. Migrations ausf√ºhren
bin/rails db:migrate

# 2. Health Check
rake scrape:check_health
```

### Production:
```bash
# Cron Job (3:00 Uhr: Scraping)
0 3 * * * cd /var/www/carambus && rake scrape:daily_update_monitored

# Cron Job (6:00 Uhr: Health Check)
0 6 * * * cd /var/www/carambus && rake scrape:check_health || mail -s "Alert" admin@example.com

# Cron Job (Sonntag: Cleanup)
0 4 * * 0 cd /var/www/carambus && rake scrape:cleanup_logs[90]
```

### W√∂chentliche Review:
```bash
# Jeden Montag: Stats der letzten Woche
rake scrape:stats

# CSV Export f√ºr Analyse
rake scrape:export_stats[7]
```

---

## üí° Warum besser als Tests?

| Aspekt | Mock-Tests | Production Monitoring |
|--------|------------|----------------------|
| **Datenquelle** | Fake Fixtures | Echte ClubCloud-Daten |
| **Fehler-Erkennung** | Nur gemockte Szenarien | Alle realen Fehler |
| **Performance** | Nicht messbar | Echte Laufzeiten |
| **Maintenance** | Hoch (Fixtures veralten) | Null (selbst-aktualisierend) |
| **Coverage** | Zeigt Test-Abdeckung | Zeigt echte Nutzung |
| **Aufwand** | 10-20 Stunden | 5 Minuten Setup |
| **Nutzen** | Begrenzt | Sehr hoch |

---

## üéâ Zusammenfassung

### Was haben wir erreicht?

‚úÖ **Real-World Monitoring** statt Mock-Tests  
‚úÖ **Automatic Exception Tracking**  
‚úÖ **Performance Monitoring**  
‚úÖ **Create/Update/Delete Stats**  
‚úÖ **Code-Coverage** (echte Produktion!)  
‚úÖ **Anomalie-Erkennung**  
‚úÖ **Web-Dashboard** (Live)  
‚úÖ **CLI Tools** (Rake Tasks)  
‚úÖ **Null Maintenance**  

### Aufwand:
- **Setup:** 5 Minuten
- **Nutzung:** `rake scrape:daily_update_monitored`
- **Auswertung:** Dashboard √∂ffnen

### Nutzen:
- ‚úÖ Sofortiges Feedback bei Problemen
- ‚úÖ Langfristige Trend-Analyse
- ‚úÖ Automatische Alerts
- ‚úÖ Professionelles Open-Source Monitoring

---

**üöÄ Ready for Production!**

*"Monitoring beats testing. Reality beats mocks."* üîç‚ú®

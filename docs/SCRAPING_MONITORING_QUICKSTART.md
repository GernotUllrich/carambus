# Scraping Monitoring - Quick Start ğŸš€

**5 Minuten Setup fÃ¼r Production-Ready Monitoring**

---

## âš¡ Setup (einmalig)

```bash
# 1. Migrations ausfÃ¼hren
cd /Volumes/EXT2TB/gullrich/DEV/carambus/carambus_master
bin/rails db:migrate

# 2. Test-Scraping mit Monitoring
rake scrape:daily_update_monitored
```

Fertig! ğŸ‰

---

## ğŸ“Š Monitoring nutzen

### Option 1: Web-Dashboard (empfohlen!)

```bash
# Server starten
bin/rails server

# Browser Ã¶ffnen
open http://localhost:3000/scraping_monitor
```

**Features:**
- âœ… Live-Ãœbersicht aller Scraping-Operationen
- ğŸ“ˆ Statistiken (7/30/90 Tage)
- âš ï¸ Automatische Anomalie-Erkennung
- ğŸ” Detail-View pro Operation
- ğŸ”„ Auto-Refresh alle 30 Sekunden

### Option 2: CLI

```bash
# Statistiken anzeigen
rake scrape:stats

# Letzte Errors
rake scrape:recent_errors

# Health Check
rake scrape:check_health
```

---

## ğŸ”„ TÃ¤glicher Betrieb

### Ersetze alten Cron Job:

```bash
# ALT (ohne Monitoring):
0 3 * * * cd /var/www/carambus && rake scrape:daily_update

# NEU (mit Monitoring):
0 3 * * * cd /var/www/carambus && rake scrape:daily_update_monitored
```

### Optional: Automatischer Health Check

```bash
# Cron: Jeden Morgen Health Check
0 6 * * * cd /var/www/carambus && rake scrape:check_health || mail -s "Scraping Alert" admin@example.com
```

---

## ğŸ“ˆ Was wird getrackt?

FÃ¼r **jede Scraping-Operation**:

| Metrik | Bedeutung |
|--------|-----------|
| `created_count` | Neue Records erstellt |
| `updated_count` | Records aktualisiert |
| `deleted_count` | Records gelÃ¶scht |
| `unchanged_count` | Records unverÃ¤ndert |
| `error_count` | Fehler aufgetreten |
| `duration` | Laufzeit in Sekunden |
| `errors_json` | VollstÃ¤ndige Exceptions + Stack Traces |

---

## ğŸš¨ Alerts & Anomalie-Erkennung

Das System erkennt automatisch:

### âš ï¸ Hohe Error-Rate
```
Erfolgsrate < 90% â†’ Alarm
```

### ğŸŒ Performance-Probleme
```
Durchschnittliche Laufzeit > 5 Min â†’ Alarm
```

### PrÃ¼fen:
```bash
rake scrape:check_health

# Output:
# âš ï¸  2 Anomalie(n) gefunden:
# 
# 1. daily_update
#    Problem: High error rate: 15%
#    Details: 10 DurchlÃ¤ufe, 150 Errors
```

---

## ğŸ” Typische Workflows

### 1. Morgens: "Wie lief das Scraping heute Nacht?"

```bash
rake scrape:stats
```

**oder**: Dashboard Ã¶ffnen: `http://localhost:3000/scraping_monitor`

### 2. Problem erkannt: "Was ist schiefgelaufen?"

```bash
# Letzte Errors ansehen
rake scrape:recent_errors

# Output zeigt:
# - Welche Operation
# - Welcher Record
# - VollstÃ¤ndige Exception + Stack Trace
```

### 3. Trend-Analyse: "Wird das System langsamer?"

```bash
# CSV Export fÃ¼r Excel/Numbers
rake scrape:export_stats[30]

# Output: tmp/scraping_stats_2026-02-15.csv
```

### 4. AufrÃ¤umen: "Alte Logs lÃ¶schen"

```bash
# Logs Ã¤lter als 90 Tage entfernen
rake scrape:cleanup_logs
```

---

## ğŸ’¡ Vorteile

### Statt aufwÃ¤ndiger Tests:

âŒ **Alt:**
```ruby
# test/scraping/tournament_scraper_test.rb
# 500 Zeilen Mock-Data
# 10 Stunden Arbeit
# Veraltet nach 2 Monaten
```

âœ… **Neu:**
```bash
# Real-World Production Monitoring
rake scrape:daily_update_monitored

# Zeigt ECHTE Probleme
# Null Maintenance
# Immer aktuell
```

---

## ğŸ¯ Code-Coverage durch Monitoring

Das Monitoring zeigt welche Methoden **tatsÃ¤chlich** aufgerufen werden:

```
ğŸ“Š ScrapeMonitor Summary: region_scraping
   Methods called: scrape_single_tournament_public, scrape_locations, scrape_clubs
```

**Besser als SimpleCov:**
- Zeigt was **wirklich lÃ¤uft** (nicht was Tests abdecken)
- Zeigt **Performance-Daten**
- Zeigt **echte Exceptions**

---

## ğŸ”§ Eigene Scraping-Methoden monitoren

### Einfache Integration:

```ruby
class MyModel < ApplicationRecord
  include ScrapeMonitor
  
  def my_scraping_method
    track_scraping("my_operation") do |monitor|
      # Dein Scraping-Code
      
      data.each do |item|
        begin
          record = create_or_update(item)
          monitor.record_created(record) if record.previously_new_record?
          monitor.record_updated(record) if record.saved_changes?
        rescue => e
          monitor.record_error(item, e)
        end
      end
    end
  end
end
```

Fertig! Jetzt erscheint `my_operation` im Dashboard.

---

## ğŸ“š Weitere Docs

- **VollstÃ¤ndige Doku**: `/docs/SCRAPING_MONITORING.md`
- **Alle Rake Tasks**: `rake -T scrape`
- **Model-Methoden**: `/app/models/scraping_log.rb`

---

## ğŸ‰ Das war's!

**3 Befehle merken:**

```bash
rake scrape:daily_update_monitored  # Scraping mit Monitoring
rake scrape:stats                   # Stats ansehen
rake scrape:check_health            # Health Check
```

**oder** einfach Dashboard Ã¶ffnen:

```
http://localhost:3000/scraping_monitor
```

---

**Happy Monitoring!** ğŸ”âœ¨
